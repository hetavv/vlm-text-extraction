# vlm-text-extraction
# VLM Assignment - MLE

This repository contains the code and results for the Vision Language Model (VLM) assignment, focusing on gujarati text extraction from scanned documents, advanced image processing, and VLM fine-tuning.

## Repository Structure

This submission is organized into three main Google Colab notebooks for clarity and reproducibility:

1.  `data_prep_and_image_enhancement.ipynb`: Handles dataset creation, ground truth generation, and advanced image processing using a GAN for image restoration.
2.  `baseline_inference.ipynb`: Performs baseline text extraction using an off-the-shelf VLM and evaluates its performance on both raw and enhanced scans.
3.  `model_fine_tuning.ipynb`: Demonstrates the fine-tuning process of the chosen VLM using parameter-efficient methods.
